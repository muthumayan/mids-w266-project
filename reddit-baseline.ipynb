{"cells":[{"cell_type":"code","source":["#@title Mount google drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A-ByPPm-uR3H","executionInfo":{"status":"ok","timestamp":1721437886415,"user_tz":420,"elapsed":1478,"user":{"displayName":"muthumayan madhayyan","userId":"09587118839465898090"}},"outputId":"d1e63fdd-e401-47f3-bff8-b1e41f33676a"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","metadata":{"id":"so-yur1S9mS4"},"source":["# Setup"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"8uQnMctL9mS5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1721437945552,"user_tz":420,"elapsed":59141,"user":{"displayName":"muthumayan madhayyan","userId":"09587118839465898090"}},"outputId":"84491f06-ec32-455d-a2f4-39b63cf4b33d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (6.0.1)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (3.9.0)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from h5py) (1.25.2)\n"]}],"source":["#@title Installs\n","!pip install pydot --quiet\n","!pip install gensim --quiet\n","!pip install tensorflow==2.15.0 --quiet #15 13\n","!pip install tf_keras==2.15.0 --quiet\n","!pip install tensorflow-datasets==4.8 --quiet #8\n","!pip install tensorflow-text==2.15.0 --quiet #15\n","!pip install transformers==4.17 --quiet #4.40.2 #4.37.2\n","!pip install pyyaml h5py"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"Q8b9aykE9mS8","executionInfo":{"status":"ok","timestamp":1721437957593,"user_tz":420,"elapsed":12047,"user":{"displayName":"muthumayan madhayyan","userId":"09587118839465898090"}}},"outputs":[],"source":["#@title Imports\n","\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","import pandas as pd\n","\n","from tensorflow.keras.layers import Embedding, Input, Dense, Lambda\n","from tensorflow.keras.models import Model\n","import tensorflow.keras.backend as K\n","from tensorflow.keras.models import load_model\n","import tensorflow_datasets as tfds\n","import tensorflow_text as tf_text\n","import transformers\n","\n","from tensorflow.keras.optimizers import Adam\n","from transformers import DistilBertTokenizerFast, TFDistilBertForSequenceClassification\n","\n","\n","from transformers import BertTokenizer, TFBertModel, BertConfig, TFBertForSequenceClassification\n","from transformers import RobertaTokenizer, TFRobertaModel\n","\n","from transformers import logging\n","logging.set_verbosity_error()\n","\n","import sklearn as sk\n","import os\n","import nltk\n","from nltk.data import find\n","\n","import matplotlib.pyplot as plt\n","\n","import re\n","\n","import gensim\n","from gensim.models import Word2Vec\n","from gensim.models import KeyedVectors\n","from gensim.test.utils import datapath"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"Zxu9U3qXMKTW","cellView":"form","executionInfo":{"status":"ok","timestamp":1721437957593,"user_tz":420,"elapsed":8,"user":{"displayName":"muthumayan madhayyan","userId":"09587118839465898090"}}},"outputs":[],"source":["#@title Global tunable parameters\n","\n","# Sequence length to truncate/pad\n","MAX_SEQUENCE_LENGTH = 512\n","\n","# hidden layer size after BERT's ouput\n","HIDDEN_LAYER_SIZE = 512"]},{"cell_type":"markdown","source":["# Utility library"],"metadata":{"id":"iRv3RZ-Viifz"}},{"cell_type":"code","source":["#@title Utility print function\n","\n","def print_version(library_name):\n","    try:\n","        lib = __import__(library_name)\n","        version = getattr(lib, '__version__', 'Version number not found')\n","        print(f\"{library_name} version: {version}\")\n","    except ImportError:\n","        print(f\"{library_name} not installed.\")\n","    except Exception as e:\n","        print(f\"An error occurred: {e}\")\n","\n","#confirm versions\n","print_version('numpy')\n","print_version('transformers')\n","print_version('tensorflow')\n","print_version('keras')\n","print_version('pandas')\n","print_version('sklearn')"],"metadata":{"id":"E7YOY6-nH9va","executionInfo":{"status":"ok","timestamp":1721437957593,"user_tz":420,"elapsed":8,"user":{"displayName":"muthumayan madhayyan","userId":"09587118839465898090"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c166e8a6-62de-44a6-ea83-630f41ec811e"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["numpy version: 1.25.2\n","transformers version: 4.17.0\n","tensorflow version: 2.15.0\n","keras version: 2.15.0\n","pandas version: 2.0.3\n","sklearn version: 1.2.2\n"]}]},{"cell_type":"code","execution_count":6,"metadata":{"id":"YKWj6pPM9mS-","cellView":"form","executionInfo":{"status":"ok","timestamp":1721437957594,"user_tz":420,"elapsed":6,"user":{"displayName":"muthumayan madhayyan","userId":"09587118839465898090"}}},"outputs":[],"source":["#@title Utility Plot Function\n","\n","# 4-window plot. Small modification from matplotlib examples.\n","\n","def make_plot(axs,\n","              model_history1,\n","              model_history2,\n","              model_1_name='model 1',\n","              model_2_name='model 2',\n","              ):\n","    box = dict(facecolor='yellow', pad=5, alpha=0.2)\n","\n","    for i, metric in enumerate(['loss', 'accuracy']):\n","        # small adjustment to account for the 2 accuracy measures in the Weighted Averging Model with Attention\n","        if 'classification_%s' % metric in model_history2.history:\n","            metric2 = 'classification_%s' % metric\n","        else:\n","            metric2 = metric\n","\n","        y_lim_lower1 = np.min(model_history1.history[metric])\n","        y_lim_lower2 = np.min(model_history2.history[metric2])\n","        y_lim_lower = min(y_lim_lower1, y_lim_lower2) * 0.9\n","\n","        y_lim_upper1 = np.max(model_history1.history[metric])\n","        y_lim_upper2 = np.max(model_history2.history[metric2])\n","        y_lim_upper = max(y_lim_upper1, y_lim_upper2) * 1.1\n","\n","        for j, model_history in enumerate([model_history1, model_history2]):\n","            model_name = [model_1_name, model_2_name][j]\n","            model_metric = [metric, metric2][j]\n","            ax1 = axs[i, j]\n","            ax1.plot(model_history.history[model_metric])\n","            ax1.plot(model_history.history['val_%s' % model_metric])\n","            ax1.set_title('%s - %s' % (metric, model_name))\n","            ax1.set_ylabel(metric, bbox=box)\n","            ax1.set_ylim(y_lim_lower, y_lim_upper)"]},{"cell_type":"markdown","source":["# Dataset preparation"],"metadata":{"id":"tsYnMLgmixFN"}},{"cell_type":"code","source":["#@title Read Reddit dataset into a dataframe\n","rdt_trainfile = '/content/drive/MyDrive/MIDS-266/w266/project/Reddit/both_train.csv'\n","rdt_tesstfile = '/content/drive/MyDrive/MIDS-266/w266/project/Reddit/both_test.csv'\n","rdt_train = pd.read_csv(rdt_trainfile)\n","rdt_test = pd.read_csv(rdt_tesstfile)\n","\n","# Shuffle all rows\n","rdt_train = rdt_train.sample(frac=1).reset_index(drop=True)\n","rdt_test = rdt_test.sample(frac=1).reset_index(drop=True)\n","\n","\n","# Split data into test and train\n","train_size = int(0.8 * len(rdt_train))\n","X_train = rdt_train[0:train_size].post\n","X_val = rdt_train[train_size:].post\n","X_test = rdt_test.post\n","y_train = rdt_train[0:train_size].class_id\n","y_val = rdt_train[train_size:].class_id\n","y_test = rdt_test.class_id\n","\n","train_labels = np.array(y_train)\n","test_labels = np.array(y_test)\n","val_labels = np.array(y_val)\n","\n","train_examples_list = []\n","test_examples_list = []\n","val_examples_list = []\n","\n","temp_train_examples = np.array(X_train)\n","temp_test_examples = np.array(X_test)\n","temp_val_examples = np.array(X_val)\n","\n","for i in range(len(temp_train_examples)):\n","  size = len(temp_train_examples[i])\n","  lower = int(0.3*MAX_SEQUENCE_LENGTH)\n","  upper = int(0.7*MAX_SEQUENCE_LENGTH)\n","  if size > MAX_SEQUENCE_LENGTH:\n","    train_examples_list.append(temp_train_examples[i][:lower] + temp_train_examples[i][upper:])\n","  else:\n","    train_examples_list.append(temp_train_examples[i])\n","\n","for i in range(len(temp_test_examples)):\n","  size = len(temp_test_examples[i])\n","  lower = int(0.3*size)\n","  upper = int(0.7*size)\n","  if size > MAX_SEQUENCE_LENGTH:\n","    test_examples_list.append(temp_test_examples[i][:lower] + temp_test_examples[i][upper:])\n","  else:\n","    test_examples_list.append(temp_test_examples[i])\n","\n","for i in range(len(temp_val_examples)):\n","  size = len(temp_val_examples[i])\n","  lower = int(0.3*size)\n","  upper = int(0.7*size)\n","  if size > MAX_SEQUENCE_LENGTH:\n","    val_examples_list.append(temp_val_examples[i][:lower] + temp_val_examples[i][upper:])\n","  else:\n","    val_examples_list.append(temp_val_examples[i])\n","\n","train_examples = np.array(train_examples_list)\n","test_examples = np.array(test_examples_list)\n","val_examples = np.array(val_examples_list)\n"],"metadata":{"id":"FX08tOHCZVs3","executionInfo":{"status":"ok","timestamp":1721437961534,"user_tz":420,"elapsed":3946,"user":{"displayName":"muthumayan madhayyan","userId":"09587118839465898090"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["print(rdt_train.class_name.unique())\n","rdt_train.class_id.unique()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ojeqVwBEiVkw","executionInfo":{"status":"ok","timestamp":1721437961535,"user_tz":420,"elapsed":5,"user":{"displayName":"muthumayan madhayyan","userId":"09587118839465898090"}},"outputId":"f75ed767-64f7-439f-a869-768c6dcfdfa3"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["['bipolar' 'depression' 'none' 'anxiety' 'adhd' 'ptsd']\n"]},{"output_type":"execute_result","data":{"text/plain":["array([2, 3, 5, 1, 0, 4])"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["rdt_train"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"MeZ9jGqTinTd","executionInfo":{"status":"ok","timestamp":1721437961815,"user_tz":420,"elapsed":283,"user":{"displayName":"muthumayan madhayyan","userId":"09587118839465898090"}},"outputId":"2043eb3f-b915-4dce-dbf2-ec5e14215bde"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                         ID  \\\n","0      cec40220-62b7-4d81-a8a1-4bb148ed0310   \n","1      27ac6825-512c-4439-8f56-5424c6fc4e5b   \n","2      8605d928-8422-4cce-956b-b03b63a8654e   \n","3      e55afe17-1b4c-4e18-a905-6d56cbf70146   \n","4      c2f74eca-c631-4c0c-89ac-0fb175718e76   \n","...                                     ...   \n","13722  d9b842d7-0bbc-43dc-919d-0f71989d69ba   \n","13723  cbf1bc7e-3b33-4231-88be-57f3d5e48fb7   \n","13724  ddfe2ee8-998d-497e-bcaa-6d1012752ef5   \n","13725  a65a1d78-dc36-4d6d-969f-a97a1a0356f4   \n","13726  a2f2bd59-622f-4a6d-a112-c21f3c5458ab   \n","\n","                                                   title  \\\n","0         how do i deal with the aftermath of hypomania?   \n","1                     anyone else just kind of existing?   \n","2      can you please point me in the direction of so...   \n","3      i hate myself and i hate that i hate myself an...   \n","4      when i immediately get downvoted after pouring...   \n","...                                                  ...   \n","13722  i’m tired of getting ideas for things to do in...   \n","13723                  why are some people so... mean :(   \n","13724                          panic attacks are back :(   \n","13725  the time between realization that you have adh...   \n","13726  8 days ago, the dnc quietly reversed its ban o...   \n","\n","                                                    post  class_name  class_id  \n","0      i cannot believe myself the past few weeks. sm...     bipolar         2  \n","1      i wake up, go to work, come home, keep myself ...  depression         3  \n","2      hello! i'm working on predictive analytics rel...        none         5  \n","3      hi whoever reads this. i've deleted at least 6...  depression         3  \n","4      makes me think twice about ever sharing on thi...  depression         3  \n","...                                                  ...         ...       ...  \n","13722  does anyone else here experience this? i have ...        adhd         0  \n","13723  i could be having a fun time and then when one...     anxiety         1  \n","13724  ‪3 days in a row with panic and several times ...     anxiety         1  \n","13725  this is not a very good post, more of a rant.....        adhd         0  \n","13726  - [international business times article from 7...        none         5  \n","\n","[13727 rows x 5 columns]"],"text/html":["\n","  <div id=\"df-f69ff042-da60-41d7-9a82-1faecf8b0369\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>title</th>\n","      <th>post</th>\n","      <th>class_name</th>\n","      <th>class_id</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>cec40220-62b7-4d81-a8a1-4bb148ed0310</td>\n","      <td>how do i deal with the aftermath of hypomania?</td>\n","      <td>i cannot believe myself the past few weeks. sm...</td>\n","      <td>bipolar</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>27ac6825-512c-4439-8f56-5424c6fc4e5b</td>\n","      <td>anyone else just kind of existing?</td>\n","      <td>i wake up, go to work, come home, keep myself ...</td>\n","      <td>depression</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>8605d928-8422-4cce-956b-b03b63a8654e</td>\n","      <td>can you please point me in the direction of so...</td>\n","      <td>hello! i'm working on predictive analytics rel...</td>\n","      <td>none</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>e55afe17-1b4c-4e18-a905-6d56cbf70146</td>\n","      <td>i hate myself and i hate that i hate myself an...</td>\n","      <td>hi whoever reads this. i've deleted at least 6...</td>\n","      <td>depression</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>c2f74eca-c631-4c0c-89ac-0fb175718e76</td>\n","      <td>when i immediately get downvoted after pouring...</td>\n","      <td>makes me think twice about ever sharing on thi...</td>\n","      <td>depression</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>13722</th>\n","      <td>d9b842d7-0bbc-43dc-919d-0f71989d69ba</td>\n","      <td>i’m tired of getting ideas for things to do in...</td>\n","      <td>does anyone else here experience this? i have ...</td>\n","      <td>adhd</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>13723</th>\n","      <td>cbf1bc7e-3b33-4231-88be-57f3d5e48fb7</td>\n","      <td>why are some people so... mean :(</td>\n","      <td>i could be having a fun time and then when one...</td>\n","      <td>anxiety</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>13724</th>\n","      <td>ddfe2ee8-998d-497e-bcaa-6d1012752ef5</td>\n","      <td>panic attacks are back :(</td>\n","      <td>‪3 days in a row with panic and several times ...</td>\n","      <td>anxiety</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>13725</th>\n","      <td>a65a1d78-dc36-4d6d-969f-a97a1a0356f4</td>\n","      <td>the time between realization that you have adh...</td>\n","      <td>this is not a very good post, more of a rant.....</td>\n","      <td>adhd</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>13726</th>\n","      <td>a2f2bd59-622f-4a6d-a112-c21f3c5458ab</td>\n","      <td>8 days ago, the dnc quietly reversed its ban o...</td>\n","      <td>- [international business times article from 7...</td>\n","      <td>none</td>\n","      <td>5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>13727 rows × 5 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f69ff042-da60-41d7-9a82-1faecf8b0369')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-f69ff042-da60-41d7-9a82-1faecf8b0369 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-f69ff042-da60-41d7-9a82-1faecf8b0369');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-193b0003-fe33-43c8-9ec0-a049ca869d24\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-193b0003-fe33-43c8-9ec0-a049ca869d24')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-193b0003-fe33-43c8-9ec0-a049ca869d24 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_2b16d123-80e5-4bba-84fa-c347d4a29142\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('rdt_train')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_2b16d123-80e5-4bba-84fa-c347d4a29142 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('rdt_train');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"rdt_train","summary":"{\n  \"name\": \"rdt_train\",\n  \"rows\": 13727,\n  \"fields\": [\n    {\n      \"column\": \"ID\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 13727,\n        \"samples\": [\n          \"b36fecf7-9da4-41e4-a690-22c783eded9a\",\n          \"8b1685a1-137c-437f-b699-ee8cf4b76d2f\",\n          \"0358122f-d644-4f30-a292-9b70cefbb08f\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 13657,\n        \"samples\": [\n          \"i think the worst part of it all is the rejection sensitive disorder. i want a different brain.\",\n          \"where is karma? this isn't fucking fair.\",\n          \"airbnb in berlin cancelled due to legislation\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"post\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 13721,\n        \"samples\": [\n          \"can't afford it at all; basically teetering on the brink of homelessness and death (naturally, i live in the united states). i really, really need to talk through what i lived through now, especially since it just finally ended, after decades. i'm talking like, serial killer level shit. real, real, real fucked up, eerie, mind-bending shit here. but since i have no insurance, and barely any money, it seems like there's nothing i can do about it. what a fate this is, eh. realistically i should be dead right now, but i survived because of a variety of rare reasons and some luck. but it's apparently not enough, because only people with money deserve to live. even though i have an education, skilled, talented... if you go down here, you're down forever if you don't have a family to help you back up. i sure as hell don't. is there any hope i can find something? thank you!\",\n          \"i just have no motivation. my life is filled up with reddit, youtube, jerking off, cutting, and trying to move past being so bad. i haven't even showered yet and it's 7pm. i don't think i've showered before 6pm on a weekend in years. edit: oh yeah, and i haven't brushed my teeth all weekend. actually, i haven't showered all weekend.\",\n          \"not sure what my intentions were posting this, but i just felt like blogging a bit about my recent trip. i'm currently in prague and have been in europe for 2.5 months. i started in madrid, took a train to barcelona, flew to porto and took a train to lisbon. after flying to amsterdam, i took trains to rotterdam, utrecht, antwerp, bruges, cologne, baumholder (us military base), nuremburg, and now prague. i've never travelled alone, in europe, or for such a long time. i've spent $2500 and using a 50 liter backpack. i've met so many beautiful people in hostels, some of whom i've developed these fascinating relationships with. i have had genuine opportunities to see all sorts of local things and stay in homes with people from the place i'm visiting. that has been the most amazing part. the willingness of some of these people to let a total stranger from the new york stay in their home and feed them and give me a place to sleep is something i've never considered. anyway, i quit my job 3 months ago and here i am a different individual. not different in the way i look at things, but rather in my development as a young person. i no longer feel obligated, cornered, or strapped down by anything. i consider myself fortunate, lucky, and optimistic. it's a beautiful tragedy, traveling. i'm in awe at where i am, what i'm doing, the people i'm with. it's heartbreaking leaving a place and the people i'm with, knowing i may very well never see them again. i know i have time to see everything, yet i know that i'll never be able to recapture the genuine feeling of experiencing it the first time. i'll never been 25 again if i return. so... i guess it's just important to acknowledge how fortunate and lucky we all are to be doing these things.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"class_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"bipolar\",\n          \"depression\",\n          \"ptsd\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"class_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 5,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          2,\n          3,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["test_examples[30]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":130},"id":"PXZv-GYrfliz","executionInfo":{"status":"ok","timestamp":1721437961815,"user_tz":420,"elapsed":12,"user":{"displayName":"muthumayan madhayyan","userId":"09587118839465898090"}},"outputId":"c85c2956-118a-48d0-89b2-fdedd53c5225"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'this scene has played out what seems like hundreds of time pretty big paper due at midnight. the thought process throughout the day: 2:00 pm: i have loads of time, no sweat. 3:00 pm: as long as i leave myself a solid 6-8 hours to finish i\\'ll be fine. 4:00 pm: i really should start working, but the sun is still up, i\\'ll be fine. 5:00 pm: shit why am i wasting so much time?! i need to start asap, but first let me make some food. 6:00 pm: okay all full and ready to start. but first lets just browse reddit quick before i start. 7:00 pm: f*** its getting so late,ay great, just gonna check reddit quick before bed. its all lies but i keep falling for it. this probably sounds like good old fashion procrastination, but i give in to even the tiniest distraction because i believe all the bs my brain tells me. the entire day i\\'m checking the clock and lying to myself. and this will happen for consecutive days. never do i say to myself, \"hey you lets not do that again.\" instead i get \"yeah yesterday was a waste, but seriously you have all day. this is probably a rant but if anyone has any suggestions i\\'d be open to anything.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["test_labels[30]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bi_I7_nHh-ix","executionInfo":{"status":"ok","timestamp":1721437961815,"user_tz":420,"elapsed":10,"user":{"displayName":"muthumayan madhayyan","userId":"09587118839465898090"}},"outputId":"cfad84a0-ff12-48f3-d687-6cf7baa64003"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wvmWKdVQ9mTC","outputId":"e5cc52ee-b327-414d-e7d3-62d51b6b220a","executionInfo":{"status":"ok","timestamp":1721437961815,"user_tz":420,"elapsed":7,"user":{"displayName":"muthumayan madhayyan","userId":"09587118839465898090"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Training set labels shape: (10981,)\n","Validation set labels shape: (2746,)\n","Test set labels shape: (1488,)\n","Training set examples shape: (10981,)\n","Validation set examples shape: (2746,)\n","Test set examples shape: (1488,)\n","Distribution of the length of all title\n","count    13727.000000\n","mean        67.111751\n","std         48.713468\n","min          2.000000\n","25%         34.000000\n","50%         54.000000\n","75%         85.000000\n","max        306.000000\n","Name: title, dtype: float64\n","Distribution of the length of all posts\n","count    13727.000000\n","mean      1065.297734\n","std       1373.414370\n","min        123.000000\n","25%        362.000000\n","50%        658.000000\n","75%       1236.500000\n","max      38168.000000\n","Name: post, dtype: float64\n","Labels min : 0 max : 5\n"]}],"source":["#@title Inspect data and label characteristics\n","\n","print(f'Training set labels shape: {train_labels.shape}')\n","print(f'Validation set labels shape: {val_labels.shape}')\n","print(f'Test set labels shape: {test_labels.shape}')\n","\n","print(f'Training set examples shape: {train_examples.shape}')\n","print(f'Validation set examples shape: {val_examples.shape}')\n","print(f'Test set examples shape: {test_examples.shape}')\n","\n","print(f'Distribution of the length of all title')\n","print(rdt_train[\"title\"].str.len().describe())\n","\n","print('Distribution of the length of all posts')\n","print(rdt_train[\"post\"].str.len().describe())\n","\n","print(f'Labels min : {rdt_train.class_id.min()} max : {rdt_train.class_id.max()}')\n"]},{"cell_type":"code","source":["#@ Histogram of all post length\n","plt.hist(rdt_train[\"post\"].str.len(), bins=10, range=(0, 10000))\n","plt.title('Distribution of post length')\n","plt.xlabel('Post length')\n","plt.ylabel('Number of posts')\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":472},"id":"tWfhBbktg_Yo","executionInfo":{"status":"ok","timestamp":1721437962389,"user_tz":420,"elapsed":579,"user":{"displayName":"muthumayan madhayyan","userId":"09587118839465898090"}},"outputId":"296bce18-d76f-4287-cec4-94e664a5604c"},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x6EAE6cjA9jM","outputId":"61544cba-8f12-4152-9990-221f8a7515fa","executionInfo":{"status":"ok","timestamp":1721437962389,"user_tz":420,"elapsed":11,"user":{"displayName":"muthumayan madhayyan","userId":"09587118839465898090"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Labels 0 in training set: 1967/10981 (0.17912758400874237)\n","Labels 1 in training set: 1946/10981 (0.17721518987341772)\n","Labels 2 in training set: 1928/10981 (0.1755759949002823)\n","Labels 3 in training set: 1960/10981 (0.17849011929696748)\n","Labels 4 in training set: 1602/10981 (0.145888352609052)\n","Labels 0 in validation set: 498/2746 (0.18135469774217042)\n","Labels 1 in validation set: 476/2746 (0.1733430444282593)\n","Labels 2 in validation set: 479/2746 (0.174435542607429)\n","Labels 3 in validation set: 490/2746 (0.17844136926438456)\n","Labels 4 in validation set: 399/2746 (0.1453022578295703)\n","Labels 0 in test set: 248/1488 (0.16666666666666666)\n","Labels 1 in test set: 248/1488 (0.16666666666666666)\n","Labels 2 in test set: 248/1488 (0.16666666666666666)\n","Labels 3 in test set: 248/1488 (0.16666666666666666)\n","Labels 4 in test set: 248/1488 (0.16666666666666666)\n"]}],"source":["#@title Distribution of labels in training and test sets\n","for i in range(np.max(train_labels)):\n","  pos_indices = np.where(train_labels == i)\n","  pct_positive = len(pos_indices[0])/len(train_labels)\n","  print(f'Labels {i} in training set: {len(pos_indices[0])}/{len(train_labels)} ({pct_positive})')\n","\n","for i in range(np.max(val_labels)):\n","  pos_indices = np.where(val_labels == i)\n","  pct_positive = len(pos_indices[0])/len(val_labels)\n","  print(f'Labels {i} in validation set: {len(pos_indices[0])}/{len(val_labels)} ({pct_positive})')\n","\n","for i in range(np.max(test_labels)):\n","  pos_indices = np.where(test_labels == i)\n","  pct_positive = len(pos_indices[0])/len(test_labels)\n","  print(f'Labels {i} in test set: {len(pos_indices[0])}/{len(test_labels)} ({pct_positive})')\n"]},{"cell_type":"code","source":["def tokenize(sentences, max_length=MAX_SEQUENCE_LENGTH, padding='max_length'):\n","    \"\"\"Tokenize using the Huggingface tokenizer\n","    Args:\n","        sentences: String or list of string to tokenize\n","        padding: Padding method ['do_not_pad'|'longest'|'max_length']\n","    \"\"\"\n","    return tokenizer(\n","        sentences,\n","        truncation=True,\n","        padding=padding,\n","        max_length=max_length,\n","        return_tensors=\"tf\"\n","    )\n"],"metadata":{"id":"WxKoJ6TjS6pY","executionInfo":{"status":"ok","timestamp":1721437962389,"user_tz":420,"elapsed":9,"user":{"displayName":"muthumayan madhayyan","userId":"09587118839465898090"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["def tokenize_data(tokenizer, input_str):\n","  tokenized = tokenizer(input_str,\n","              max_length=MAX_SEQUENCE_LENGTH,\n","              truncation=True,\n","              padding='max_length',\n","              return_tensors='tf')\n","  return tokenized"],"metadata":{"id":"o2WyCOfbzHKW","executionInfo":{"status":"ok","timestamp":1721437962390,"user_tz":420,"elapsed":10,"user":{"displayName":"muthumayan madhayyan","userId":"09587118839465898090"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","execution_count":17,"metadata":{"id":"cpSk9zvw532w","executionInfo":{"status":"ok","timestamp":1721437962390,"user_tz":420,"elapsed":9,"user":{"displayName":"muthumayan madhayyan","userId":"09587118839465898090"}}},"outputs":[],"source":["#@title BERT Tokenization of training, validation and test data\n","\n","def tokenize_train_val(tokenizer, train_examples, val_examples):\n","\n","    train_examples_str = [x for x in train_examples]\n","    val_examples_str = [x for x in val_examples]\n","\n","    # Tokenize training, validation and test data\n","    bert_train_tokenized = tokenize_data(tokenizer, train_examples_str)\n","    bert_val_tokenized = tokenize_data(tokenizer, val_examples_str)\n","\n","    bert_train_inputs = [bert_train_tokenized.input_ids,\n","                        bert_train_tokenized.token_type_ids,\n","                        bert_train_tokenized.attention_mask]\n","\n","\n","    bert_val_inputs = [bert_val_tokenized.input_ids,\n","                        bert_val_tokenized.token_type_ids,\n","                        bert_val_tokenized.attention_mask]\n","\n","\n","    return bert_train_inputs, bert_val_inputs"]},{"cell_type":"markdown","source":["# BERT Model"],"metadata":{"id":"cliFsGhujEeg"}},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"status":"ok","timestamp":1721437962390,"user_tz":420,"elapsed":9,"user":{"displayName":"muthumayan madhayyan","userId":"09587118839465898090"}},"id":"qpG8xukeMaFb"},"outputs":[],"source":["#@title BERT Tokenization of training, validation and test data\n","\n","def tokenize_test(tokenizer, test_examples):\n","\n","    test_examples_str = [x for x in test_examples]\n","\n","    # Tokenize training, validation and test data\n","    bert_test_tokenized = tokenize_data(tokenizer, test_examples_str)\n","\n","    bert_test_inputs = [bert_test_tokenized.input_ids,\n","                        bert_test_tokenized.token_type_ids,\n","                        bert_test_tokenized.attention_mask]\n","\n","\n","    return bert_test_inputs"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"V1OAGPTNgPr6","executionInfo":{"status":"ok","timestamp":1721437962390,"user_tz":420,"elapsed":9,"user":{"displayName":"muthumayan madhayyan","userId":"09587118839465898090"}}},"outputs":[],"source":["\n","#@title Train BERT model using CLS token\n","def create_bert_cls_model(bert_base_model,\n","                          max_sequence_length=MAX_SEQUENCE_LENGTH,\n","                          hidden_size = 100,\n","                          dropout=0.3,\n","                          learning_rate=0.00005):\n","    \"\"\"\n","    Build a simple classification model with BERT. Use the CLS Token output for classification purposes.\n","    \"\"\"\n","\n","    bert_base_model.trainable = True\n","\n","    input_ids = tf.keras.layers.Input(shape=(max_sequence_length,), dtype=tf.int64, name='input_ids_layer')\n","    token_type_ids = tf.keras.layers.Input(shape=(max_sequence_length,), dtype=tf.int64, name='token_type_ids_layer')\n","    attention_mask = tf.keras.layers.Input(shape=(max_sequence_length,), dtype=tf.int64, name='attention_mask_layer')\n","\n","    bert_inputs = {'input_ids': input_ids,\n","                   'token_type_ids': token_type_ids,\n","                   'attention_mask': attention_mask}\n","\n","    bert_out = bert_base_model(bert_inputs)\n","\n","    # The first token of every example is a CLS token\n","    cls_embedding = bert_out[0][:, 0, :]\n","    print(cls_embedding.shape)\n","\n","    hidden = tf.keras.layers.Dense(hidden_size, activation='relu', name='hidden_layer')(cls_embedding)\n","\n","    hidden = tf.keras.layers.Dropout(dropout)(hidden)\n","\n","    classification = tf.keras.layers.Dense(6, activation='softmax',name='classification_layer')(hidden)\n","\n","    classification_model = tf.keras.Model(inputs=[input_ids, token_type_ids, attention_mask], outputs=[classification])\n","\n","    classification_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n","                                 loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n","                                 metrics='accuracy')\n","\n","    return classification_model\n","\n","\n","def bert_main(train, val, tlabels, vlabels, fraction):\n","    \"\"\"\n","    Main function to train BERT model\n","    \"\"\"\n","    # Load BERT model\n","    config_l = BertConfig.from_pretrained(\"bert-base-cased\")\n","    config_l.num_max_position_embeddingslabels = 1024\n","    bert_model = TFBertModel.from_pretrained('bert-base-cased', config = config_l)\n","\n","    # Load training, validation and test data\n","    train_samples = train[0:int(fraction*len(train))]\n","    val_samples = val[0:int(fraction*len(val))]\n","\n","    # Tokenize training, validation and test data\n","    bert_tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n","    bert_train_inputs, bert_val_inputs = tokenize_train_val(bert_tokenizer, train_samples, val_samples)\n","\n","    # Convert labels to numpy arrays\n","    bert_train_labels = np.array(tlabels)\n","    bert_train_sample_labels = bert_train_labels[0:int(fraction*len(tlabels))]\n","\n","    bert_val_labels = np.array(vlabels)\n","    bert_val_sample_labels = bert_val_labels[0:int(fraction*len(vlabels))]\n","\n","    # Create classification model\n","    bert_avg_model = create_bert_cls_model(bert_model, hidden_size=HIDDEN_LAYER_SIZE)\n","\n","    bert_avg_model.summary()\n","\n","    bert_avg_model_history = bert_avg_model.fit(\n","        bert_train_inputs,\n","        bert_train_sample_labels,\n","        validation_data=(bert_val_inputs, bert_val_sample_labels),\n","        batch_size=12,\n","        epochs=2)\n","\n","    return bert_avg_model, bert_avg_model_history"]},{"cell_type":"markdown","source":["# Distilbert"],"metadata":{"id":"Caj1e-BjjSWH"}},{"cell_type":"code","source":["\n","\n","def distilbert_main(train, val, tlabels, vlabels, fraction):\n","    \"\"\"\n","    Main function to train distilbert model\n","    \"\"\"\n","\n","    LEARNING_RATE = 5e-5\n","    BATCH_SIZE = 16\n","    NUM_EPOCHS = 3\n","\n","    NUM_LABELS = np.max(tlabels) + 1\n","    model = TFDistilBertForSequenceClassification.from_pretrained(\n","        'distilbert-base-uncased',\n","        num_labels= NUM_LABELS)\n","\n","    # Load training, validation and test data\n","    tsamples = train[0:int(fraction*len(train))]\n","    train_samples = tsamples.tolist()\n","    vsamples = val[0:int(fraction*len(val))]\n","    val_samples = vsamples.tolist()\n","\n","    # Convert labels to numpy arrays\n","    train_labels = np.array(tlabels)\n","    train_sample_labels = train_labels[0:int(fraction*len(tlabels))]\n","\n","    val_labels = np.array(vlabels)\n","    val_sample_labels = val_labels[0:int(fraction*len(vlabels))]\n","\n","    # Tokenize training, validation and test data\n","    distilbert_tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n","\n","    train_dataset = tf.data.Dataset.from_tensor_slices((\n","        dict(tokenize_data(distilbert_tokenizer, train_samples)),  # Convert BatchEncoding instance to dictionary\n","        train_sample_labels)).shuffle(1000).batch(BATCH_SIZE).prefetch(1)\n","\n","    val_dataset = tf.data.Dataset.from_tensor_slices((\n","        dict(tokenize_data(distilbert_tokenizer, val_samples)),  # Convert BatchEncoding instance to dictionary\n","        val_sample_labels)).batch(BATCH_SIZE).prefetch(1)\n","\n","    optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n","    model.compile(\n","        optimizer=optimizer,\n","        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","        metrics='accuracy')\n","\n","    model.summary()\n","\n","    model_history = model.fit(\n","        train_dataset,\n","        y=None,\n","        validation_data=val_dataset,\n","        batch_size=BATCH_SIZE,\n","        epochs=NUM_EPOCHS)\n","\n","    return model, model_history\n","\n"],"metadata":{"id":"GK2uZD8_IVri","executionInfo":{"status":"ok","timestamp":1721437962390,"user_tz":420,"elapsed":8,"user":{"displayName":"muthumayan madhayyan","userId":"09587118839465898090"}}},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":["# Roberta"],"metadata":{"id":"_7UiOxBfjaLs"}},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"status":"ok","timestamp":1721437962390,"user_tz":420,"elapsed":8,"user":{"displayName":"muthumayan madhayyan","userId":"09587118839465898090"}},"id":"F0JnPnPukbFH"},"outputs":[],"source":["#@title BERT Tokenization of training, validation and test data\n","\n","def roberta_tokenize_train_val(tokenizer, train_examples, val_examples):\n","\n","    train_examples_str = [x for x in train_examples]\n","    val_examples_str = [x for x in val_examples]\n","\n","    # Tokenize training, validation and test data\n","    train_tokenized = tokenize_data(tokenizer, train_examples_str)\n","    val_tokenized = tokenize_data(tokenizer, val_examples_str)\n","\n","    train_inputs = [train_tokenized.input_ids,\n","                        train_tokenized.attention_mask]\n","\n","\n","    val_inputs = [val_tokenized.input_ids,\n","                        val_tokenized.attention_mask]\n","\n","\n","    return train_inputs, val_inputs"]},{"cell_type":"code","execution_count":35,"metadata":{"id":"0XKTJtpZHwXH","executionInfo":{"status":"ok","timestamp":1721440750932,"user_tz":420,"elapsed":201,"user":{"displayName":"muthumayan madhayyan","userId":"09587118839465898090"}}},"outputs":[],"source":["#@title Train RoBERTa model - use CLS token\n","def create_roberta_cls_model(bert_base_model,\n","                          max_sequence_length=MAX_SEQUENCE_LENGTH,\n","                          hidden_size = 100,\n","                          dropout=0.3,\n","                          learning_rate=0.00005):\n","    \"\"\"\n","    Build a simple classification model with BERT. Use the CLS Token output for classification purposes.\n","    \"\"\"\n","\n","    bert_base_model.trainable = True\n","\n","    input_ids = tf.keras.layers.Input(shape=(max_sequence_length,), dtype=tf.int64, name='input_ids_layer')\n","    attention_mask = tf.keras.layers.Input(shape=(max_sequence_length,), dtype=tf.int64, name='attention_mask_layer')\n","\n","    bert_inputs = {'input_ids': input_ids,\n","                   'attention_mask': attention_mask}\n","\n","    bert_out = bert_base_model(bert_inputs)\n","\n","    # The first token of every example is a CLS token\n","    cls_embedding = bert_out[0][:, 0, :]\n","    print(cls_embedding.shape)\n","\n","    hidden = tf.keras.layers.Dense(hidden_size, activation='relu', name='hidden_layer')(cls_embedding)\n","\n","    hidden = tf.keras.layers.Dropout(dropout)(hidden)\n","\n","    classification = tf.keras.layers.Dense(6, activation='softmax',name='classification_layer')(hidden)\n","\n","    classification_model = tf.keras.Model(inputs=[input_ids, attention_mask], outputs=[classification])\n","\n","    classification_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n","                                 loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n","                                 metrics='accuracy')\n","\n","    return classification_model\n","\n","\n"]},{"cell_type":"code","execution_count":36,"metadata":{"executionInfo":{"status":"ok","timestamp":1721440755252,"user_tz":420,"elapsed":213,"user":{"displayName":"muthumayan madhayyan","userId":"09587118839465898090"}},"id":"xRnqUYVCf5HG"},"outputs":[],"source":["def roberta_main(train, val, tlabels, vlabels, fraction):\n","    \"\"\"\n","    Main function to train RoBerta model\n","    \"\"\"\n","\n","    # Load training, validation and test data\n","    tsamples = train[0:int(fraction*len(train))]\n","    vsamples = val[0:int(fraction*len(val))]\n","\n","    train_samples = tsamples\n","    val_samples = vsamples\n","\n","    # Tokenize training, validation and test data\n","    roberta_tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n","    roberta_train_inputs, roberta_val_inputs = roberta_tokenize_train_val(roberta_tokenizer, train_samples, val_samples)\n","\n","    # Convert labels to numpy arrays\n","    roberta_train_labels = np.array(tlabels)\n","    roberta_train_sample_labels = roberta_train_labels[0:int(fraction*len(tlabels))]\n","\n","    roberta_val_labels = np.array(vlabels)\n","    roberta_val_sample_labels = roberta_val_labels[0:int(fraction*len(vlabels))]\n","\n","    # Create classification model\n","    config_l = BertConfig.from_pretrained(\"roberta-base\")\n","    config_l.num_max_position_embeddingslabels = 512\n","\n","    roberta_model = TFRobertaModel.from_pretrained('roberta-base', config = config_l)\n","    roberta_classification_model = create_roberta_cls_model(roberta_model, hidden_size=HIDDEN_LAYER_SIZE)\n","\n","    roberta_classification_model.summary()\n","\n","    roberta_classification_model_history = roberta_classification_model.fit(\n","        roberta_train_inputs,\n","        roberta_train_sample_labels,\n","        validation_data=(roberta_val_inputs, roberta_val_sample_labels),\n","        batch_size=8,\n","        epochs=2\n","    )\n","\n","    return roberta_classification_model, roberta_classification_model_history\n"]},{"cell_type":"code","source":[],"metadata":{"id":"qzW7wsPRu0IH","executionInfo":{"status":"ok","timestamp":1721437962391,"user_tz":420,"elapsed":7,"user":{"displayName":"muthumayan madhayyan","userId":"09587118839465898090"}}},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":["# Main Control loop"],"metadata":{"id":"kZwf-TRRu1BR"}},{"cell_type":"code","source":["def train(train_examples, val_examples, train_labels, val_labels, fraction, input_model):\n","  match input_model:\n","      case 1:\n","          model, model_history = bert_main(train_examples, val_examples, train_labels, val_labels, fraction)\n","\n","      case 2:\n","          model, model_history = distilbert_main(train_examples, val_examples, train_labels, val_labels, fraction)\n","\n","      case 3:\n","          model, model_history = roberta_main(train_examples, val_examples, train_labels, val_labels, fraction)\n","\n","      case 4:\n","          roberta_attention_main()\n","\n","      case _:\n","          print(\"Invalid input\")\n","\n","  # Save the model\n","  path = f'./saved_models/{input_model}/'\n","  if not os.path.exists(path):\n","    os.makedirs(path, exist_ok=True)\n","  tf.keras.models.save_model(model, path)\n","  #model.save(f'{path}/model.keras')\n","\n","  return model, model_history\n","\n","def predict(test_examples, test_labels, model_type, model):\n","  \"\"\"\n","  Test the model on the test set\n","  \"\"\"\n","\n","  from sklearn.metrics import confusion_matrix\n","\n","  #Predict\n","  match model_type:\n","      case 1:\n","        bert_tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n","        test_tokens = tokenize_test(bert_tokenizer, test_examples)\n","        y_prediction = model.predict(test_tokens)\n","\n","      case 2:\n","        distilbert_tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n","        test_examples_list = test_examples.tolist()\n","        test_tokens = tokenize_data(distilbert_tokenizer, test_examples_list)\n","        y_prediction = model.predict((dict(test_tokens),)) # Pass a tuple to predict\n","        # Extract the NumPy array from the dictionary\n","        y_prediction = y_prediction[0] # Extract the NumPy array\n","\n","      case 3:\n","        roberta_tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n","        test_examples_list = test_examples.tolist()\n","        test_tokens = tokenize_data(roberta_tokenizer, test_examples_list)\n","        y_prediction = model.predict((test_tokens['input_ids'], test_tokens['attention_mask']))\n","\n","  # Convert predicted probabilities to class labels\n","  y_prediction = np.argmax(y_prediction, axis=1) # Convert probabilities to discrete class labels\n","\n","  #Create confusion matrix and normalizes it over predicted (columns)\n","  result = confusion_matrix(test_labels, y_prediction , normalize='pred')\n","  print(result)\n","\n","  return\n","\n","\n","def train_model():\n","  print('Enter the type of model to train: ')\n","  print('1. BERT with custom classifier')\n","  print('2. Distilbert')\n","  print('3. Roberta')\n","  print('4. Roberta with Attention')\n","\n","  model_type = input()\n","  model_type = int(model_type)\n","\n","  if model_type > 4:\n","    print('Invalid input')\n","    return\n","\n","  print('Enter the fraction of the data to use: ')\n","  fraction = input()\n","  fraction = float(fraction)\n","\n","  if fraction > 1:\n","    print('Invalid input')\n","    return\n","\n","  model, model_history = train(train_examples, val_examples, \\\n","                               train_labels, val_labels, \\\n","                               fraction, model_type)\n","\n","  return model, model_type, model_history\n","\n","def load_my_model():\n","\n","  print('Enter my custom saved modelbased of: ')\n","  print('1. BERT with custom classifier')\n","  print('2. Distilbert')\n","  print('3. Roberta')\n","  print('4. Roberta with Attention')\n","  model_type = input()\n","  model_type = int(model_type)\n","\n","  if model_type > 4:\n","    print('Invalid input')\n","    return\n","\n","  path = f'./saved_models/{model_type}/'\n","  if not os.path.exists(path):\n","    print('Model not found')\n","    return\n","  print(f'Loading model from {path}')\n","  lmodel = keras.models.load_model(path)\n","\n","  return lmodel\n","\n","\n","# initialization\n","model_type = 0\n","model_history = None\n","model = None\n","\n","if __name__ == '__main__':\n","  while True:\n","      print('Task selection menu')\n","      print('What task do you want to do [4]:')\n","      print('1. Load my fine tuned reddit posts model')\n","      print('2. Train (fine-tune) a base model')\n","      print('3. Run prediction on test dataset')\n","      print('4. Quit')\n","\n","      task = input()\n","      task = int(task)\n","\n","      if task >= 4:\n","        print(f'Invalid input {task}')\n","        break\n","\n","      match(task):\n","        case 1:\n","          model = load_my_model()\n","          model.summary()\n","\n","        case 2:\n","          model, model_type, model_history = train_model()\n","\n","        case 3:\n","          if model is None or model_type == 0:\n","            print('Model not loaded')\n","            break\n","          predict(test_examples, test_labels, model_type, model)\n","\n","        case _:\n","          print('Invalid input')\n","          break\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":657},"id":"JX7r0nx-tuw8","executionInfo":{"status":"error","timestamp":1721440781859,"user_tz":420,"elapsed":21247,"user":{"displayName":"muthumayan madhayyan","userId":"09587118839465898090"}},"outputId":"abc9b4ee-68cf-46ac-aef3-d0c1f2bc81bf"},"execution_count":37,"outputs":[{"name":"stdout","output_type":"stream","text":["Task selection menu\n","What task do you want to do [4]:\n","1. Load my fine tuned reddit posts model\n","2. Train (fine-tune) a base model\n","3. Run prediction on test dataset\n","4. Quit\n","2\n","Enter the type of model to train: \n","1. BERT with custom classifier\n","2. Distilbert\n","3. Roberta\n","4. Roberta with Attention\n","3\n","Enter the fraction of the data to use: \n","0.03\n"]},{"output_type":"error","ename":"AttributeError","evalue":"'TFRobertaModel' object has no attribute 'bert'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-37-f6631f006f81>\u001b[0m in \u001b[0;36m<cell line: 122>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mcase\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m           \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mcase\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-37-f6631f006f81>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m   model, model_history = train(train_examples, val_examples, \\\n\u001b[0m\u001b[1;32m     88\u001b[0m                                \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                                fraction, model_type)\n","\u001b[0;32m<ipython-input-37-f6631f006f81>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_examples, val_examples, train_labels, val_labels, fraction, input_model)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m       \u001b[0mcase\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m           \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroberta_main\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_examples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_examples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfraction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m       \u001b[0mcase\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-36-5ca1641b08eb>\u001b[0m in \u001b[0;36mroberta_main\u001b[0;34m(train, val, tlabels, vlabels, fraction)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mroberta_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTFRobertaModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'roberta-base'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig_l\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mroberta_classification_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_roberta_cls_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroberta_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mHIDDEN_LAYER_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mroberta_classification_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-35-677b09b301af>\u001b[0m in \u001b[0;36mcreate_roberta_cls_model\u001b[0;34m(bert_base_model, max_sequence_length, hidden_size, dropout, learning_rate)\u001b[0m\n\u001b[1;32m     17\u001b[0m                    'attention_mask': attention_mask}\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mbert_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert_base_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# The first token of every example is a CLS token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'TFRobertaModel' object has no attribute 'bert'"]}]},{"cell_type":"code","source":["model.summary()"],"metadata":{"id":"03dXtgmHadxH","executionInfo":{"status":"ok","timestamp":1721438296816,"user_tz":420,"elapsed":22,"user":{"displayName":"muthumayan madhayyan","userId":"09587118839465898090"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"021a0615-7954-44e1-94e9-ae22659d334b"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                Output Shape                 Param #   Connected to                  \n","==================================================================================================\n"," attention_mask_layer (Inpu  [(None, 512)]                0         []                            \n"," tLayer)                                                                                          \n","                                                                                                  \n"," input_ids_layer (InputLaye  [(None, 512)]                0         []                            \n"," r)                                                                                               \n","                                                                                                  \n"," tf_roberta_model (TFRobert  TFBaseModelOutputWithPooli   1246456   ['attention_mask_layer[0][0]',\n"," aModel)                     ngAndCrossAttentions(last_   32         'input_ids_layer[0][0]']     \n","                             hidden_state=(None, 512, 7                                           \n","                             68),                                                                 \n","                              pooler_output=(None, 768)                                           \n","                             , past_key_values=None, hi                                           \n","                             dden_states=None, attentio                                           \n","                             ns=None, cross_attentions=                                           \n","                             None)                                                                \n","                                                                                                  \n"," tf.__operators__.getitem (  (None, 768)                  0         ['tf_roberta_model[0][0]']    \n"," SlicingOpLambda)                                                                                 \n","                                                                                                  \n"," hidden_layer (Dense)        (None, 512)                  393728    ['tf.__operators__.getitem[0][\n","                                                                    0]']                          \n","                                                                                                  \n"," dropout_37 (Dropout)        (None, 512)                  0         ['hidden_layer[0][0]']        \n","                                                                                                  \n"," classification_layer (Dens  (None, 6)                    3078      ['dropout_37[0][0]']          \n"," e)                                                                                               \n","                                                                                                  \n","==================================================================================================\n","Total params: 125042438 (477.00 MB)\n","Trainable params: 125042438 (477.00 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","__________________________________________________________________________________________________\n"]}]},{"cell_type":"code","execution_count":26,"metadata":{"id":"O-MMBGCWLwe1","executionInfo":{"status":"ok","timestamp":1721438296817,"user_tz":420,"elapsed":13,"user":{"displayName":"muthumayan madhayyan","userId":"09587118839465898090"}}},"outputs":[],"source":["#fig, axs = plt.subplots(2, 2)\n","#fig.subplots_adjust(left=0.2, wspace=0.6)\n","#make_plot(axs,\n","#          dan_shuffled_history,\n","#          wan_history,\n","#          model_1_name='dan',\n","#          model_2_name='wan')\n","\n","#fig.align_ylabels(axs[:, 1])\n","#fig.set_size_inches(18.5, 10.5)\n","#plt.show()"]},{"cell_type":"code","source":["!ls saved_models/3"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YjBn59_YpYzS","executionInfo":{"status":"ok","timestamp":1721438307397,"user_tz":420,"elapsed":406,"user":{"displayName":"muthumayan madhayyan","userId":"09587118839465898090"}},"outputId":"d3560e71-5bf0-4d3f-ecec-041c58aa0aa9"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["assets\tfingerprint.pb\tkeras_metadata.pb  saved_model.pb  variables\n"]}]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4","collapsed_sections":["iRv3RZ-Viifz","Caj1e-BjjSWH"]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}